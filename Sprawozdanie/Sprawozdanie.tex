\documentclass[10pt,a4paper]{article}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{hhline}
\usepackage{pgfplots}
\usepackage{multicol}
%\usepackage{slashbox}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{colortbl}
\usepackage{geometry}
\usepackage{listings}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\geometry{a4paper, total={170mm,257mm}, left=20mm, top=20mm }
\lstset
{
    language=C++,
    basicstyle=\footnotesize,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}
\author{Sebastian Maciejewski 132275 i Jan Techner 132332\\
grupa I1, zajęcia we wtorki o 15:10, tygodnie nieparzyste,\\
email: maciejewski.torun@gmail.com}
\title{Porównywanie efektywności metod mnożenia macierzy}
\date{30 kwietnia 2019}
\setlength{\parindent}{0pt}
\newcommand{\forceindent}{\leavevmode{\parindent=3em\indent}}
\begin{document}
\maketitle
\section{Wstęp}
Sprawozdanie dotyczy zadania w wariancie 22. - porównywanie efektywności metod
mnożenia macierzy:\\
- dla 3 pętli kolejność jki, podział pracy przed 1. pętlą\\
- dla 6 pętli kolejność pętli zewnętrznych ijk, wewnętrznych iijjkk,
podział pracy przed 4. pętlą\\
\\
Wszystkie pomiary zostały wykonane na komputerach laboratoryjnych w sali 2.7.6.
\section{Analiza przygotowania eksperymentu}
\subsection{Kod wykorzystywany przy pomiarach}
Kod, którego używaliśmy w eksperymencie został tak podzielony, aby cała
logika przetwarzania znajdowała się w pojedynczej funkcji. Poniżej prezentowany
jest kod tylko tych funkcji - generowanie macierzy i wypełnianie jej
losowymi liczbami, liczenie czasu i wypisywanie wyników działają w ten
sam sposób dla wszystkich wariantów przetwarzania.
\subsubsection{Metoda 3 pętli - równolegle}
\begin{lstlisting}
    void multiply_matrices_JKI()
    {
    #pragma omp parallel for 
        for (int j = 0; j < COLUMNS; j++)
            for (int k = 0; k < COLUMNS; k++)
                for (int i = 0; i < ROWS; i++)
                    matrix_r[i][j] += matrix_a[i][k] * matrix_b[k][j];
    }
\end{lstlisting}

\subsubsection{Metoda 3 pętli - sekwencyjnie}
\begin{lstlisting}
    void multiply_matrices_IKJ_sequentially() 
    {
        for (int i = 0; i < ROWS; i++)
            for (int k = 0; k < COLUMNS; k++)   
                for (int j = 0; j < COLUMNS; j++)
                    matrix_r[i][j] += matrix_a[i][k] * matrix_b[k][j];
    }
\end{lstlisting}

\subsubsection{Metoda 6 pętli - równolegle}
\begin{lstlisting}
    void multiply_matrices_IJK_IIJJKK()
    {
        int r = 10;
        for (int i = 0; i < ROWS; i += r)
            for (int j = 0; j < COLUMNS; j += r)
                for (int k = 0; k < COLUMNS; k += r)
    #pragma omp parallel for
                    for (int ii = i; ii < i + r; ii++)
                        for (int jj = j; jj < j + r; jj++)
                            for (int kk = k; kk < k + r; kk++)
                                matrix_r[ii][jj] += matrix_a[ii][kk] * matrix_b[kk][jj];
    }
\end{lstlisting}
\newpage

\subsection{Analiza podziału pracy na wątki}
\subsubsection{Dyrektywy OpenMP}
W naszym kodzie używamy dyrektyw 'pragma omp parallel for', które sprawiają, że iteracje pętli
będą wykonane w sposób równoległy przez kilka wątków. Każdy z wątków wykona jednakowy zakres
iteracji, w naszym wypadku, przy podziale na 4 wątki, pierwszy wątek wykona pierwszą $\frac{1}{4}$
operacji, drugi kolejną itd. Dopiero po zakończeniu przetwarzania przez wszystkie wątki następuje
synchronizacja i przejście dalej - do zakończenia pomiaru czasu.

\subsubsection{Analiza ryzyka wystąpienia wyścigu i zjawiska false sharingu}

\subsubsection*{Wyścig}

Zjawisko wyścigu, czyli równoległa modyfikacja tej samej zmiennej przez różne procesy, nie
występuje w naszym kodzie.\\
Aby się o tym przekonać wystarczy zwrócić na to, że w naszym przypadku,
w równoległym przetwarzaniu dla 3 pętli mamy zapis do $matrix\_r[i][j]$, gdzie wartości $j$ są
dzielone pomiędzy procesy z powodu wystąpienia dyrektywy 'parallel for' przed pętlą odpowiedzialną
za inkrementację licznika kolumn $j$ (2.1.1, linijki od 3 do 7). Co za tym idzie każdy proces zawsze zapisuje do innej kolumny
niż pozostałe, więc zjawisko wyścigu nie występuje w tym przypadku.\\
Podobna sytuacja występuje przy 6 pętlach - każdy proces zapisuje do osobnego wiersza z powodu
wystąpienia dyrektywy 'parallel for' przed pętlą odpowiedzialną za inkrementację zmiennej $ii$
(2.1.3, linijki od 7 do 11) - w tym przypadku również nie dojdzie do wyścigu.

\subsubsection*{False sharing}
Inaczej sytuacja ma się w przypadku zjawiska false sharingu. False sharing występuje wtedy, gdy
różne procesy zapisują zmienne znajdujące się w tej samej linii pamięci - wówczas kopie linii
w pamięciach podręcznych innych procesów stają się nieaktualne i dany proces musi ponownie pobrać
linię z pamięci aby zapewnić spójność pamięci podręcznej. To zajmuje czas, więc takie zjawisko
jest nieporządane, gdyż wpływa negatywnie na efektywność przetwarzania.\\
Długość linii pamięci w systemach, na których wykonywane były pomiary to 64B, zatem w każdej
linii pamięci mieści się 16 zmiennych typu float, używanych prez nas w obliczeniach. Rozmiary
instancji w naszych pomiarach były $\geq 400$. Mając to na uwadze, możemy się zająć analizą ryzyka
wystąpienia zjawiska false sharingu.\\

W wersji przetwarzania równolegle dla 3 pętli mamy do czynienia z podziałem pracy przed 1. pętlą, $j$,
która odpowiada za licznik kolumn.
Z uwagi na to, iż każdy z procesów zapisuje dane jedynie do swojej kolumny macierzy wynikowej, 
zjawisko false sharingu nie wystąpi gdyż szerokość zbioru kolumn przetwarzanych przez jeden wątek jest
znacznie większa od długości jednej linii pamięci - dla instancji o wielkości 400, każdy wątek będzie
zapisywał dane do zbioru 100 kolumn, gdzie w jednym wierszu takiego zbioru zmieści się prawie 7 całych linii pamięci. \\
Jedynym miejscem, w którym to zjawisko może wystapić są brzegi zbiorów kolumn przetwarzanych przez wątki, kiedy linia pamięci 
zawiera elementy wiersza należące do zbioru kolumn dwóch różnych wątków. Jednakże biorąc pod uwagę to, że wątki przetwarzają kolumny
sekwencyjnie, przesuwając się w lewo (zgodnie ze zmienna $j$), nawet jeżeli linia pamięci zawierająca ostatnie elementy zbioru kolumn przetwarzanych 
przez wątek będzie zawierała elementy z następnego zbioru innego wątku, to te elementy już zostały przez ten wątek zapisane i linia pamięci zawierająca 
te elementy została już zastąpiona przez nową linię, zawierającą elementy dalej na lewo w macierzy C.  \\

Natomiast w wersji 6-pętlowej zjawisko false-sharingu nie występuje, ponieważ każdy wątek zapisuje dane do swojego 
zbioru wierszy fragmentu $r \times r$ macierzy C i i nie ma możliwości, żeby linia pamięci zawierała elementy wierszy przetwarzanych przez
dwa różne wątki.

\newpage

\subsubsection{Podział przetwarzania w metodzie 3-pętlowej}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{3loops1.png}
	\caption{Obszar danych dla jednej wewnętrznej pętli $i$}
\end{figure}

Każdy wątek przy przechodzeniu ostatniej pętli odwołuje się do jednej kolumny macierzy wynikowej C (odwołanie następuje do elementu
$matrix\_r[i][j]$, gdzie zmianna $j$ jest stała dla ostatniej pętli), analogicznie dla macierzy A (w tym przypadku dla elementu $matrix\_a[i][k]$
nie zmienia się zmienna $k$). Przy przechodzeniu ostatniej pętli dla macierzy B, obie zmienne określające element $matrix\_b[k][j]$ są stałe, więc 
wątki odwołują się tylko do jednego elementu macierzy B.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{3loops2.png}
	\caption{Obszar danych dla dwóch wewnętrznych pętli $k$ i $i$}
\end{figure}

Dla dwóch pętli każdy wątek przetwarza $k$ razy tą samą kolumnę macierzy C, co w przypadku jednej pętli, wszystkie kolumny 
macierzy A oraz wszystkie elementy z $j$-tej kolumny macierzy C (zmienna $j$ jest cały czas stała).\\

Rozważając wszystkie pętle i podział pracy między wątkami, każdy wątek będzie po kolei przetwarzał kolejne kolumny macierzy C (wyznaczane przez 
zmienną $j$), odpowiadające im kolumny macierzy B oraz każdorazowo całą macierz A.

\newpage

\subsubsection{Podział przetwarzania w metodzie 6-pętlowej}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{6loops1.png}
	\caption{Obszar danych dla pętli $kk$}
\end{figure}

Przy przetwarzaniu ostatniej wewnętrznej pętli każdy wątek przetwarza jeden element macierzy C (zmienia się tylko zmienna $kk$, a odwołania następują do 
elementu $matrix\_r[ii][jj]$), jeden cały wiersz o szerokości $r$ macierzy A (zmienna $ii$ pozostaje stała przy odwoływaniu się do elementu $matrix\_a[ii][kk]$) oraz 
do jednej kolumny o wysokości $r$ macierzy B (przy odwoływaniu się do elementu $matrix\_b[kk][jj]$ zmienna $jj$ pozostaje stała).

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{6loops2.png}
	\caption{Obszar danych dla pętli $jj$, $kk$}
\end{figure}

Rozpatrując dwie pętle wewnętrzne, zmieniają się zmienne $jj$ i $kk$, czyli przy przetwarzaniu macierzy C zmieniane będą elementy z jednego wiersza 
o szerokości $r$, $r$-krotnie przetwarzany będzie wiersz o szerokości $r$ macierzy A oraz wszystkie elementy fragmentu $r \times r$ macierzy B. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{6loops3.png}
	\caption{Obszar danych dla pętli $ii$, $jj$, $kk$}
\end{figure}

Dla 3 pętli wewnętrznych zmieniają się już wszystkie zmienne $ii$, $jj$ i $kk$, więc przetworzone zostaną wszystkie wiersze fragmentu $r \times r$
macierzy wynikowej C (odpowiada za to zmienna $ii$), wszystkie wiersze odpowiadającego fragmentu macierzy A oraz $r$ - krotnie przetworzone zostaną 
wszystkie elementy fragmenu $r \times r$ macierzy B. \\

Podział pracy w naszym przypadku odbywa się przed pętlą $ii$, więc każdy wątek będzie przetwarzał grupę wierszy z fragmentu $r \times r$ macierzy C, 
odpowiadający mu fragment macierzy A oraz wielkrotnie cały fragment $r \times r$ macierzy B.

\newpage

\subsection{Analiza lokalności czasowej}
Znaczącym czynnikiem mającym wpływ na efektywność przetwarzania jest czas dostępu do
danych. Ten czas jest znacznie krótszy przy dostępie podręczniej pamięci procesora niż
przy konieczności odwołania się do pamięci RAM. Bardzo ograniczona pojemność pamięci
podręcznej sprawia, że kod powinien być pisany w taki sposób, aby maksymalizować
wykorzystanie danych już załadowancyh do pamięci podręcznej i minimalizować ilość
odczytów z RAM. Przetwarzanie jest efektywne wtedy, gdy kod charakteryzuje się
czasową lokalnością odwołań do pamięci, czyli wielokrotnym wykorzystaniem danych załadowanych
do pamięci podręcznej zanim zostaną zastąpione innymi danymi odczytanymi z RAM.\\
Zakładamy, że rozmiar pamięci podręcznej procesora, na którym przeprowadzane są
obliczenia to 6 MB. Jest to pojemność pamięci L3 - L2 nie jest tu brane pod uwagę,
ponieważ część danych obecnych w niej pokrywa się z danymi w L3. Również pamięć L1
jest przy tym założeniu pomijana, ponieważ jej pojemność jest tak mała, że jej uwzględnianie
nie miało by znaczącego wpływu na obliczane wielkośći instancji.\\
Przy obliczeniach zakładamy, że 1 MB = 1000 KB = 1000000 B, przy czym pojedyncza zmienna typu
float, z których korzystamy, ma rozmiar 4 B.\\
\\
Dla metody \textbf{3 pętli} wzór, którego używamy do obliczania rozmiaru instancji, dla której
będzie zachowana lokalność czasowa to:
\begin{equation}
	n^2 * 4B + 2 * n * 64B \leq \frac{6000000B}{4}
\end{equation}
przy czym $n$ to rozmiar instancji.\\\\
Warunek zachowania lokalności czasowej będzie spełniony jeżeli pamięć podręczna pomieści:
\begin{enumerate} \itemsep0pt
	\item[a)] jedną kolumnę macierzy C (zajmowana pamięć wyniesie $n * 64B$, ponieważ macierz jest w pamięci 
	      przechowywana wierszami i każdy element kolumny będzie w innej linii pamięci)
	\item[b)] całą macierz A (zajmowana pamięć wyniesie $n^2 * 4$B - macierz zawiera $n^2$ elementów po 4B każdy)
	\item[c)] jedną kolumnę macierzy B (zajmowana pamięć wyniesie $n * 64B$, analogicznie do punktu a).
\end{enumerate}
Wielkość pamięci podręcznej w systemie, na którym przeprowadzane były doświadczenia wynosi 6MB i 
jest to pamięć współdzielona pomiędzy 4 rdzeniami procesora. Stąd też suma wielkości pamięci podręcznej 
wymaganej do przechowania potrzebnych elementów każdej macierzy powinna być mniejsza niż czwarta 
część całej pamięci podręcznej w systemie.\\
Po rozwiązaniu nierówności uzyskana wartość $n$ rozmiaru instancji, dla której wciąż będzie zachowana
lokalność czasowa to w przybliżeniu $n \leq 596$.\\

Dla metody \textbf{6 pętli} wzór do obliczenia rozmiaru instancji ma postać:
\begin{equation}
	3*r^2 * 4B \leq 6000000B
\end{equation}
gdzie $r$ to rozmiar wykorzystywanego bloku, pobieranego każdorazowo z macierzy.\\

Każdy z wątków przetwarzania potrzebuje stałego dostepu do fragmentu macierzy B o rozmiarze $r \times r$, ponieważ
ten fragment czytany jest wielokrotnie przez każdy wątek podczas kolejnych iteracji. Dodatkowo każdy wątek odczytuje 
dane z kolejnych wierszy fragmentu macierzy A i zapisuje do kolejnych wierszy fragmentu macierzy wynikowej C, 
więc w pamięci podręcznej należy umieścić również $r \times r$ elementów dla macierzy C i $r \times r$ elementów 
dla macierzy A (jest to pewne uproszczenie obliczeń, ponieważ każdy wątek w kolejnych iteracjach potrzebuje 
dostępu tylko do wierszy fragmentów macierzy C i A, ale ostatecznie wszystkie wiersze z obu fragmentów zostaną
wykorzystane, więc bezpiecznie jest trzymać je wszystkie od razu w pamięci podręcznej). Łącznie więc w pamięci 
podręcznej musimy przechować 3 fragmenty zawierające $r \times r$ elementów po 4B każdy.\\

Wyznaczona wartość $r$, dla której będzie zachowana lokalność czasowa to $r \leq 707$.

\subsection{Analiza lokalności przestrzennej}
Lokalność przestrzenna jest związana z występowaniem w systemie pamięci wirtualnej.
Jest mechanizm, który umożliwia procesowi pracę w jednym, ciągłym obszarze pamięci operacyjnej,
nawet gdy fizycznie jest ona pofragmentowana lub część z niej znajduje się w pliku wymiany,
który procesy mogą wykorzystać jako dodatkową pamięć w przypadku, gdy w systemie brakuje
fizycznej pamięci operacyjnej. Pamięć wirtualna niesie ze sobą pewne konsekwencje -
najważniejszą z nich jest to, że teraz procesy muszą posługiwać się adresami logicznymi
zamiast fizycznymi adresami mającymi bezpośrednie odwzorowanie w pamięci RAM.
Taka pamięć jest dzielona na strony o rozmiarze 4 kB, które stanowią jeden, ciągły obszar w pamięci.
Aby taki system mógł działać, pamięć RAM jest dzielona na ramki, których rozmiar odpowiada
rozmiarowi stron. Strony mogą się znajdować w pamięci lub we wspomnianym wyżej pliku wymiany,
co sprawia, że procesor musi posługiwać się logicznymi adresami aby uzyskać dostęp do danych.\\

Taka organizacja pamięci wymusza obecność mechanizmu tłumaczenia adresów logicznych
na fizyczne, czyli odwzorowania adresów strony na adres ramki pamięci. Informacje o takich
odwzorowaniach znajdują się w tablicy stron. W tym miejscu stosuje się pewne usprawnienie, jako, że
przeglądanie takiej tablicy przy każdym odwołaniu byłoby bardzo mało wydajne. Tym usprawnieniem
jest bufor translacji adresu TLB, który posiada określoną, stałą liczbę adresów stron i odpowiadającyh
im ramek, dzięki czemu można szybko dokonać translacji adresu logicznego na fizyczny.
Jednak tak jak w pamięci podręcznej, tak i w buforze translacji występuje ograniczenie rozmiaru.\\

Program chechuje się zachowaniem lokalności przestrzennej wtedy, kiedy nie występują sytuacje,
w których w buforze translacji nie znajduje się adres szukanej strony. W procesorze, z którego
korzystaliśmy przy obliczeniach bufor translacji mieści 544 pary adres strony - adres ramki.
Każda ze stron pamięci wirtualnej ma rozmiar 4 kB, tak więc mieści 1024 liczby z wykorzystywanej
przez nas macierzy.\\

Aby znaleźć wielkośći instancji, dla których przetwarzanie zachowa lokalność przestrzenną dla
\textbf{3 pętli} posłużyliśmy się wzorem:
\begin{equation}
	\ceil*{\frac{n^2}{1024}} + 2 * min\Big(n, \ceil*{\frac{n^2}{1024}}\Big) \leq 544
\end{equation}
gdzie $n$ to rozmiar instancji.\\

Pierwszy człon reprezentuje liczbę stron zawierających wszystkie elementy macierzy A, natomiast kolejny
to dwukrotność (człon jest identyczny dla macierzy B i C) liczby stron zawierających jedną kolumnę macierzy.
Jeżeli rozmiar macierzy $n$ przekracza 1024 elementy, to każdy element kolumny macierzy będzie na innej stronie,
więc, żeby zapewnić dostęp do całej kolumny, potrzebne będą 1024 strony. Jeżeli zaś rozmiar macierzy będzie
mniejszy od 1024, to może zdarzyć się, że dwa kolejne elementy macierzy będą znajdowały się na tej samej 
stronie i liczba stron potrzebnych do zawarcia całej kolumny będzie taka sama jak w przypadku macierzy A.\\

Po rozwiązaniu nierówności, wartość $n$, dla której będzie zachowana lokalność przestrzenna to $n \leq 430$.
\\

Dla \textbf{6 pętli} wzór na znalezienie takich wartośći $n$ i $r$, dla których przetwarzanie zachowa
lokalność przestrzenną, wygląda następująco:
\begin{equation}
	min\Big(r, \frac{r*n}{1024}\Big) + 2*min\Big(\frac{r}{4}, \frac{\frac{r}{4} * n}{1024}\Big) \leq 544
\end{equation}

gdzie $n$ to rozmiar instancji, a $r$ to rozmiar wykorzystywanego bloku.\\

W przypadku 6 pętli lokalność przestrzenna zależy zarówno od rozmiaru instancji $n$, jak i od rozmiaru 
okna $r$. Każdy wątek przetwarzania potrzebuje dostępu do $r \times r$ elementów fragmentu macierzy B oraz
dwóch fragmentów $r \times \frac{r}{4}$ macierzy C i A. Liczba stron potrzebnych do dostępu do wszystkich 
elementów fragmentu macierzy B to $r$ (jeżeli $n \leq 1024$ - każdy wiersz znajduje się na osobnej stronie) 
lub $r*n / 1024$ (w przeciwnym wypadku - kilka wierszy może znajdować się na tej samej stronie). Liczbę stron 
dla mniejszych fragmentów macierzy C i A można obliczyć w analogiczny sposób, z tym, że w tym przypadku rozpatrywany
fragment będzie miał wysokość $r/4$ zamiast $r$.\\

W naszych pomiarach przyjęliśmy, że rozmiar instancji będzie większy od 1024 (przyjęliśmy 1500).
Po podstawieniu wartości 1500 w miejsce $n$ we wzorze i rozwiązaniu nierówności, wartość $r$, przy której 
zostanie zachowana lokalność przestrzenna to $r \leq 362$.
\\
\section{Analiza wyników eksperymentu pomiarowego}
\subsection{Wstępny opis eksperymentu pomiarowego}
Eksperyment został przeprowadzony na komputerach w sali laboratoryjnej 2.7.6 przy
wykorzystaniu funkcji opisanych w punkcie 2.1 wywoływanych w programie, którego jedynym
zadaniem poza wywołaniem wymienionych wyżej funkcji było losowanie macierzy
(na początku, przed rozpocżeciem pomiaru czasu) i mierzenie czasu przetwarzania
(na podstawie stanu zegara przed i po wywołaniu funkcji). Po podaniu wielkości instancji
i kompilacji programu poddawaliśmy go analizie w programie CodeXL. Ogólnie mierzone (lub dane)
były następujące wielkości:
\begin{center}
	\begin{tabular}{ |c|c|c| }
		\hline
		Zmienna                                      & Oznaczenie & Wartość progu \\
		\hline
		Wielkość instancji                         & n          &                 \\
		Wielkość okna                              & r          &                 \\
		Czas przetwarzania                           & Tobl       &                 \\
		Liczba instrukcji assemblera                 & LIA        & 250 000         \\
		Liczba cykli procesora                       & LCP        & 250 000         \\
		Liczba dostępów do L1                      & LDP        & 250 000         \\
		Liczba braków trafień do L3                & BTL3       & 50 000          \\
		Liczba braków trafień do bufora translacji & BTBT       & 50 000          \\
		\hline
	\end{tabular}
	\captionof{table}{Oznaczenia i progi zmiennych}
\end{center}
Wielkością instancji określamy rozmiar mnożonej macierzy kwadratowej.
Pomiary wykonaliśmy dla następujących instancji:
\begin{itemize}
	\item 3 pętle - rozmiar macierzy 400, 450, 550, 600, 700
	\item 6 pętli - rozmiar macierzy 1500 + rozmiar okna 100, 300, 400, 500, 750 oraz \\rozmiar macierzy 2000 + rozmiar okna 200
\end{itemize}

Pomiary zbierane były w taki sposób, aby nie uruchamiać na raz analizy zbyt wielu
parametrów, gdyż mogłoby to zakłócić wyniki. Aby tego uniknąć mierzyliśmy najpierw 
LDP, BTL3 i BTBT, a dopiero później LIA i LCP. Odczytane wyniki zapisywaliśmy do 
załączonego arkusza kalkulacyjnego. Dokonaliśmy też wstępnej analizy instrukcji
assemblera, które składały się na nasz program aby zobaczyć które z nich najbardziej
obciążały procesor (było ich najwięcej).
\subsection{Wyniki uzyskane w eksperymencie}
\begin{center}
	\begin{tabular}{ |c|c|c|c|c|c|c|c| }
		\hline
		n   & Tobl  & LIA  & LCP   & LDP  & BTL3 & BTBT \\
		\hline
		400 & 0.078 & 1413 & 1871  & 925  & 35   & 1    \\
		\hline
		450 & 0.109 & 1980 & 4914  & 1329 & 53   & 16   \\
		\hline
		550 & 0.289 & 3566 & 15405 & 2370 & 113  & 1036 \\
		\hline
		600 & 0.625 & 4554 & 29754 & 3159 & 136  & 2697 \\
		\hline
		700 & 1.683 & 6856 & 77515 & 4999 & 349  & 7458 \\
		\hline
	\end{tabular}
	\captionof{table}{Wyniki dla 3 pętli, przetwarzanie równolegle}
\end{center}

\begin{center}
	\begin{tabular}{ |c|c|c|c|c|c|c|c|c| }
		\hline
		n    & r   & Tobl   & LIA    & LCP    & LDP   & BTL3 & BTBT  \\
		\hline
		1500 & 100 & 1.5780 & 233901 & 97207  & 33332 & 2688 & 44    \\
		\hline
		1500 & 300 & 2.6770 & 105947 & 131667 & 33506 & 2002 & 153   \\
		\hline
		1500 & 400 & 4.4530 & 98107  & 232887 & 87960 & 1192 & 653   \\
		\hline
		1500 & 500 & 2.9530 & 241691 & 154389 & 31834 & 720  & 7617  \\
		\hline
		1500 & 750 & 7.3280 & 101394 & 366565 & 31171 & 1086 & 40351 \\
		\hline
		2000 & 200 & 3.6700 & 242986 & 204930 & 74343 & 2825 & 69    \\
		\hline
	\end{tabular}
	\captionof{table}{Wyniki dla 6 pętli, przetwarzanie równolegle}
\end{center}

\begin{center}
	\begin{tabular}{ |c|c|c|c|c|c|c|c| }
		\hline
		n   & Tobl   & LIA  & LCP  & LDP  & BTL3 & BTBT \\
		\hline
		400 & 0.0310 & 774  & 582  & 375  & 18   & 1    \\
		\hline
		450 & 0.0630 & 1073 & 832  & 602  & 17   & 1    \\
		\hline
		550 & 0.0940 & 1877 & 1431 & 1060 & 24   & 1    \\
		\hline
		600 & 0.0940 & 2329 & 1577 & 1097 & 23   & 0    \\
		\hline
		700 & 0.1660 & 3616 & 2441 & 1685 & 42   & 3    \\
		\hline
		800 & 0.2340 & 5299 & 3534 & 2454 & 42   & 8    \\
		\hline
	\end{tabular}
	\captionof{table}{Wyniki dla 3 pętli, przetwarzanie sekwencyjne}
\end{center}

\subsection{Miary efektywności}
W celu analizy jakości przetwarzania stosujemy opisane następującymi
wzorami miary efektywności:\\
\subsubsection*{Prędkość przetwarzania}
\begin{equation}
	PP = \frac{2 * n^3}{Tobl}
\end{equation}
\subsubsection*{Liczba instrukcji na cykl procesora IPC1 dla procesora}
\begin{equation}
	IPC1 = \frac{LIA}{LCP}
\end{equation}
\subsubsection*{Liczba instrukcji na cykl procesora IPCS dla systemu}
\begin{equation}
	IPCS = \frac{LIA*LPF}{LCP}
\end{equation}
\subsubsection*{Wskaźnik braków trafień do pamięci podręcznej L3}
\begin{equation}
	WBTL3 = \frac{BTL3}{LIA}
\end{equation}
\subsubsection*{Wskaźnik dostępu do danych}
\begin{equation}
	WDD = \frac{LDP}{LIA}
\end{equation}
\subsubsection*{Wskaźnik braków trafień do głównego bufora translacji adresów}
\begin{equation}
	WBTBT = \frac{BTBT}{LDP}
\end{equation}
\subsubsection*{Krotność pobierania danych instancji do pamięci podręcznej}
\begin{equation}
	KPD = \frac{BTL3 * 64}{4 * 3 * n * n}
\end{equation}
\subsubsection*{Miara kosztu synchronizacji}
\begin{equation}
	MKS = \frac{CCP - CWP}{CCP} = \frac{LUPF * Tobl - LCP * Tclk}{LUPF * Tobl}
\end{equation}
Gdzie $LUPF$ to liczba użytych procesorów fizycznych (liczba wątków OMP), a $Tclk$ 
to czas trwania cyklu zegara procesora w sekundach.
\subsubsection*{Przyspieszenie przetwarzania równoległego}
\begin{equation}
	Sp(rownolegle\: A) = \frac{Tobl(obliczenia \: sekwencyjne \: IKJ)}{Tobl(obliczenia \: rownolegle \: A)}
\end{equation}
\\
\subsubsection*{Komentarz do miar efektywności}
Przy obliczaniu $KPD$ można wydzielić dwa skrajne przypadki: \\
- w optymistycznym przypadku każda linia pamięci zostanie pobrana dokładnie raz,
stąd $KPD$ w takim przypadku to $KPD = 1$\\
- w pesymistycznym przypadku w każdej iteracji algorytmu z trzema pętlami wystąpi
brak trafienia do pamięci dla każdej z macierzy, wówczas $$KPD = \frac{3n^3 * 64}{4 * 3n^2}
= 16 n^2$$

\subsection{Obliczone miary efektywności}
\begin{center}
	\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| }
		\hline
		n   & PP [GFLOPS] & IPC1   & IPCS   & WBTL3    & WDD    & WBTBT    & KPD      & MKS & Sp     \\
		\hline
		400 & 1,6410      & 0,7552 & 3,0208 & 4,95E-03 & 0,6546 & 2,16E-04 & 58,3333  &     & 0,3974 \\
		\hline
		450 & 1,6720      & 0,4029 & 1,6117 & 5,35E-03 & 0,6712 & 2,41E-03 & 69,7942  &     & 0,5780 \\
		\hline
		550 & 1,1514      & 0,2315 & 0,9259 & 6,34E-03 & 0,6646 & 8,74E-02 & 99,6143  &     & 0,3253 \\
		\hline
		600 & 0,6912      & 0,1531 & 0,6122 & 5,97E-03 & 0,6937 & 1,71E-01 & 100,7407 &     & 0,1504 \\
		\hline
		700 & 0,4076      & 0,0884 & 0,3538 & 1,02E-02 & 0,7291 & 2,98E-01 & 189,9320 &     & 0,0986 \\
		\hline
	\end{tabular}
	\captionof{table}{Miary efektywności dla 3 pętli, przetwarzanie równolegle}
\end{center}

\begin{center}
	\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| }
		\hline
		n    & r   & PP [GFLOPS] & IPC1   & IPCS   & WBTL3    & WDD    & WBTBT    & KPD      & MKS \\
		\hline
		1500 & 100 & 4,2776      & 2,4062 & 9,6249 & 2,30E-03 & 0,1425 & 2,64E-04 & 318,5778 &     \\
		\hline
		1500 & 300 & 2,5215      & 0,8047 & 3,2186 & 3,78E-03 & 0,3163 & 9,13E-04 & 237,2741 &     \\
		\hline
		1500 & 400 & 1,5158      & 0,4213 & 1,6851 & 2,43E-03 & 0,8966 & 1,48E-03 & 141,2741 &     \\
		\hline
		1500 & 500 & 2,2858      & 1,5655 & 6,2619 & 5,96E-04 & 0,1317 & 4,79E-02 & 85,3333  &     \\
		\hline
		1500 & 750 & 0,9211      & 0,2766 & 1,1064 & 2,14E-03 & 0,3074 & 2,59E-01 & 128,7111 &     \\
		\hline
		2000 & 200 & 4,3597      & 1,1857 & 4,7428 & 2,33E-03 & 0,3060 & 1,86E-04 & 188,3333 &     \\
		\hline
	\end{tabular}
	\captionof{table}{Miary efektywności dla 6 pętli, przetwarzanie równolegle}
\end{center}

\subsection*{Graficzna prezentacja pewnych zależności}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{PP.JPG}
	\caption{Porównanie PP w GFLOPS dla przetwarzania równoległego i sekwencyjnego}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{Tobl.JPG}
	\caption{Porównanie Tobl w sekundach dla przetwarzania równoległego i sekwencyjnego}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{SP.JPG}
	\caption{Zależność SP od wielkości instancji dla metody równoległej z 3 pętlami}
\end{figure}

\section{Wnioski}

\end{document}